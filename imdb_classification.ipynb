{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация отзывов на фильмы IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Задача:** научиться отличать позитивные отзывы от негативных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала импортируем все, что нам понадобиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from nltk import pos_tag, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для предобработки текстов для алгоритмов классического ML, будем пользоваться библиотекой NLTK. Подгрузим необходимые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt') # для токенизации\n",
    "nltk.download('averaged_perceptron_tagger') # для разметки частей речи\n",
    "nltk.download('wordnet') # для лемматизации\n",
    "nltk.download('stopwords') # для удаления ненужных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим обучающие данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.texts') as file:\n",
    "    train_texts = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.labels') as file:\n",
    "    train_labels = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If the myth regarding broken mirrors would be accurate, everybody involved in this production would now face approximately 170 years of bad luck, because there are a lot of mirrors falling to little pieces here. If only the script was as shattering as the glass, then \"The Broken\" would have been a brilliant film. Now it\\'s sadly just an overlong, derivative and dull movie with only just a handful of remarkable ideas and memorable sequences. Sean Ellis made a very stylish and elegantly photographed movie, but the story is lackluster and the total absence of logic and explanation is really frustrating. I got into a discussion with a friend regarding the basic concept and \"meaning\" of the film. He thinks Ellis found inspiration in an old legend claiming that spotting your doppelganger is a foreboding of how you\\'re going to die. Interesting theory, but I\\'m not familiar with this legend and couldn\\'t find anything on the Internet about this, neither. Personally, I just think \"The Broken\" is yet another umpteenth variation on the theme of \"Invasion of the Body Snatchers\" but without the alien interference. \"The Broken\" centers on the American McVey family living in London, and particularly Gina. When a mirror spontaneously breaks during a birthday celebration, this triggers a whole series of mysterious and seemingly supernatural events. Gina spots herself driving by in a car and follows her mirror image to an apartment building. Whilst driving home in a state of mental confusion, she causes a terrible car accident and ends up in the hospital. When dismissed, Gina feels like her whole surrounding is changing. She doesn\\'t recognize her own boyfriend anymore and uncanny fragments of the accident keep flashing before her eyes. Does she suffer from mental traumas invoked by the accident or is there really a supernatural conspiracy happening all around her? Writer/director Sean Ellis definitely invokes feelings of curiosity and suspense in his script, but unfortunately he fails to properly elaborate them. \"The Broken\" is a truly atmospheric and stylish effort, but only after just half an hour of film, you come to the painful conclusion it shall just remain a beautiful but empty package. There\\'s a frustratingly high amount of \"fake\" suspense in this film. This means building up tension, through ominous music and eerie camera angels, when absolutely nothing has even happened so far. By the time the actually mysteriousness kicks in, these tricks don\\'t have any scary effect on you anymore. Some of my fellow reviewers around here compare the film and particularly Sean Ellis\\' style with the repertoires of David Lynch, Stanley Kubrick and even Alfred Hitchcock, but that is way, way \\x85  WAY too much honor. PS: what is up with that alternate spelling; the one with the Scandinavian \"ø\"'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем 2 вспомогательные функции: для препроцессинга и для перевода обозначения частей речи к формату wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Transform parts of speech to wordnet format.\n",
    "    '''\n",
    "    switch = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'V': wordnet.VERB,\n",
    "        'N': wordnet.NOUN,\n",
    "        'R': wordnet.ADV,\n",
    "    }\n",
    "    for key, item in switch.items():\n",
    "        if treebank_tag.startswith(key):\n",
    "            return item\n",
    "    return wordnet.NOUN\n",
    "\n",
    "def preprocess(sent, stop_words):\n",
    "    '''\n",
    "    Preprocessing from raw text to lemmatized text.\n",
    "    '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sanitized_sent = ' '.join(re.findall(r\"\\b[A-Za-z]+\\b\", sent)) # удалим все, что не слова английского языка\n",
    "    tokenized_sent = word_tokenize(sanitized_sent) # токенизируем\n",
    "    pos_tagged = [(word, get_wordnet_pos(tag)) # разметим части речи\n",
    "                 for word, tag in pos_tag(tokenized_sent)]\n",
    "    lemmatized_sent = [lemmatizer.lemmatize(word, tag) # приведем к одной форме (лемматизируем)\n",
    "                    for word, tag in pos_tagged]\n",
    "    reduced_sent = [word for word in lemmatized_sent if word not in stop_words] # уберем стоп-слова\n",
    "    return ' '.join(reduced_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем текст, выкидываем слова, не несущие смысловой нагрузки, делаем TF-IDF векторизацию. При этом будем брать н-граммы от 1 до 3 и ограничим число итоговых признаков до 20000 (подбиралось вручную)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "processed = [preprocess(sent, stop_words) for sent in train_texts]\n",
    "labels = [0 if label == 'neg' else 1 for label in train_labels]\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=20000)\n",
    "vectorizer.fit(processed)\n",
    "vectorized = vectorizer.transform(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем логистическую регрессию по кросс-валидации, подберем параметр l2 регуляризации, а затем обучим на всем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871333333333332\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=3, max_iter=500)\n",
    "print((np.mean(cross_val_score(lr, vectorized, labels, scoring=\"accuracy\", cv=5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=3, max_iter=500)\n",
    "lr.fit(vectorized, labels)\n",
    "\n",
    "test_df = pd.read_csv('texts.csv')\n",
    "test_texts = test_df['texts'].to_list()\n",
    "test_texts = [preprocess(sent, stop_words) for sent in test_texts]\n",
    "test = vectorizer.transform(test_texts)\n",
    "lr_predictions = lr.predict(test)\n",
    "test_df['labels'] = ['neg' if pred == 0 else 'pos' for pred in  cat_predictions]\n",
    "test_df[['id', 'labels']].to_csv('y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Собственно, все мое SOTA решение)\n",
    "\n",
    "## Кратко о том, что не сработало"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотелось на тех же TF-IDF векторах обучить Catboost, но почему-то сработало хуже линейной модели. Была идея подобрать гиперпараметры с помощью Optuna, но времени не хватило. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08424101f62f4647970366ae905d8241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.8673333333\n",
      "bestIteration = 1355\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.8503333333\n",
      "bestIteration = 1338\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.8706666667\n",
      "bestIteration = 1954\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.8543333333\n",
      "bestIteration = 889\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.8603333333\n",
      "bestIteration = 1707\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-Accuracy-mean</th>\n",
       "      <th>test-Accuracy-std</th>\n",
       "      <th>train-Accuracy-mean</th>\n",
       "      <th>train-Accuracy-std</th>\n",
       "      <th>test-CrossEntropy-mean</th>\n",
       "      <th>test-CrossEntropy-std</th>\n",
       "      <th>train-CrossEntropy-mean</th>\n",
       "      <th>train-CrossEntropy-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.704867</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.707350</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.684720</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.684483</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.677199</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.676759</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.715667</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>0.716250</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.669943</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.669454</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.716533</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.663185</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.662546</td>\n",
       "      <td>0.001088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.717933</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>0.720383</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.655975</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.655220</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>0.859267</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>0.974767</td>\n",
       "      <td>0.017623</td>\n",
       "      <td>0.332684</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.182775</td>\n",
       "      <td>0.029206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.859267</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>0.974783</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>0.332688</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.182761</td>\n",
       "      <td>0.029224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.859267</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>0.974783</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>0.332682</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.182745</td>\n",
       "      <td>0.029244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.859200</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.974800</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.332683</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.182732</td>\n",
       "      <td>0.029260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.859200</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>0.332683</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.182728</td>\n",
       "      <td>0.029265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iterations  test-Accuracy-mean  test-Accuracy-std  train-Accuracy-mean  \\\n",
       "0              0            0.704867           0.013952             0.707350   \n",
       "1              1            0.709600           0.013041             0.713967   \n",
       "2              2            0.715667           0.012730             0.716250   \n",
       "3              3            0.715200           0.013201             0.716533   \n",
       "4              4            0.717933           0.011658             0.720383   \n",
       "...          ...                 ...                ...                  ...   \n",
       "1995        1995            0.859267           0.008877             0.974767   \n",
       "1996        1996            0.859267           0.008877             0.974783   \n",
       "1997        1997            0.859267           0.008877             0.974783   \n",
       "1998        1998            0.859200           0.008774             0.974800   \n",
       "1999        1999            0.859200           0.008774             0.974817   \n",
       "\n",
       "      train-Accuracy-std  test-CrossEntropy-mean  test-CrossEntropy-std  \\\n",
       "0               0.008670                0.684720               0.000463   \n",
       "1               0.008048                0.677199               0.000672   \n",
       "2               0.003764                0.669943               0.001088   \n",
       "3               0.005375                0.663185               0.001750   \n",
       "4               0.004667                0.655975               0.001788   \n",
       "...                  ...                     ...                    ...   \n",
       "1995            0.017623                0.332684               0.006487   \n",
       "1996            0.017642                0.332688               0.006483   \n",
       "1997            0.017642                0.332682               0.006491   \n",
       "1998            0.017661                0.332683               0.006489   \n",
       "1999            0.017681                0.332683               0.006490   \n",
       "\n",
       "      train-CrossEntropy-mean  train-CrossEntropy-std  \n",
       "0                    0.684483                0.000314  \n",
       "1                    0.676759                0.000369  \n",
       "2                    0.669454                0.000547  \n",
       "3                    0.662546                0.001088  \n",
       "4                    0.655220                0.000853  \n",
       "...                       ...                     ...  \n",
       "1995                 0.182775                0.029206  \n",
       "1996                 0.182761                0.029224  \n",
       "1997                 0.182745                0.029244  \n",
       "1998                 0.182732                0.029260  \n",
       "1999                 0.182728                0.029265  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'verbose': False, 'iterations': 2000, 'loss_function': 'CrossEntropy', 'od_wait': 200, 'eval_metric': 'Accuracy'}\n",
    "pool = Pool(data=vectorized, label=labels)\n",
    "cv(pool, params, fold_count=5, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее пробуем подход с предобученным трансформером - distilled BERT\n",
    "\n",
    "Импортируем все необходимое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим необходимые объекты: tokenizer для токенизации, collator для составления батчей и саму модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем вспомогательные функции для токенизации и рассчета accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(examples):\n",
    "    '''\n",
    "    Tokenizes text.\n",
    "    '''\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "    \n",
    "def compute_metrics(eval_pred):\n",
    "    '''\n",
    "    Computes accuracy.\n",
    "    '''\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем данные в формат для transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_dict({'label': labels, 'text': train_texts})\n",
    "ds = ds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f066ca74f67e4ebc97c7ff83d1f31cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c8030f44b54a0d963e6c48cac97e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(preprocessing, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, зафайнтюним наш BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 30:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280100</td>\n",
       "      <td>0.230696</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.347833</td>\n",
       "      <td>0.914667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.23519743347167968, metrics={'train_runtime': 1840.7675, 'train_samples_per_second': 13.038, 'train_steps_per_second': 1.63, 'total_flos': 2994117145956384.0, 'train_loss': 0.23519743347167968, 'epoch': 2.0})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distbert1\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество выглядит многообещающим, но на тесте ничего хорошего не вышло.\n",
    "\n",
    "Далее применяем модель к тестовым данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 10/10000 [00:00<06:25, 25.95it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████| 10000/10000 [06:58<00:00, 23.89it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_preds = []\n",
    "bad_counter = 0\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distbert1/checkpoint-3000\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distbert1/checkpoint-3000\")\n",
    "for txt in tqdm(test_texts):\n",
    "    tokenized_txt = tokenizer(txt, return_tensors=\"pt\")\n",
    "    if tokenized_txt['input_ids'].shape[1] > 512: # в тесте оказались примеры длиннее, чем может обработать модель, они просто обрезались\n",
    "        tokenized_txt['input_ids'] = tokenized_txt['input_ids'][:, :512]\n",
    "        tokenized_txt['attention_mask'] = tokenized_txt['attention_mask'][:, :512]\n",
    "        bad_counter += 1\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokenized_txt).logits\n",
    "        predicted_class_id = logits.argmax().item()\n",
    "        ans = model.config.id2label[predicted_class_id]\n",
    "    if ans == 'NEGATIVE':\n",
    "        bert_preds.append('neg')\n",
    "    else:\n",
    "        bert_preds.append('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('texts.csv')\n",
    "test_df['labels'] = bert_preds\n",
    "test_df[['id', 'labels']].to_csv('y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоследок попробуем построить **стэкинг** из разных базовых моделей, в качетсве финальной - логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = LogisticRegression(penalty='l2', C=3, max_iter=500) # логрег с l2 регуляризацией и коэффициентом 3\n",
    "l2_2 = LogisticRegression(penalty='l2', C=1, max_iter=500) # логрег с l2 регуляризацией и коэффициентом 1\n",
    "l2_3 = LogisticRegression(penalty='l2', C=5, max_iter=500) # логрег с l2 регуляризацией и коэффициентом 5\n",
    "fin = LogisticRegression(penalty='l2', C=3, max_iter=500) # финальный логрег\n",
    "l1 = LogisticRegression(penalty='l1', C=3, solver='saga', max_iter=500) # логрег с l1 регуляризацией и коэффициентом 3\n",
    "lr = LogisticRegression(penalty=None, max_iter=500) # логрег без регуляризации\n",
    "naive = MultinomialNB() # наивный байесовский классификатор\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=7, random_state=42, n_jobs=8) # случайный лес\n",
    "estimators = [('l2', l2), ('l2_2', l2_2), ('l2_3', l2_3), ('l1', l1), ('lr', lr), ('naive', naive),\n",
    "('rf_simple', rf_simple)]\n",
    "cls = StackingClassifier(estimators=estimators, final_estimator=fin, n_jobs=8, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.fit(vectorized, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_predictions = cls.predict(test)\n",
    "test_df['labels'] = ['neg' if pred == 0 else 'pos' for pred in  stack_predictions]\n",
    "test_df[['id', 'labels']].to_csv('y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже ничего прорывного на тесте из этого не вышло"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
